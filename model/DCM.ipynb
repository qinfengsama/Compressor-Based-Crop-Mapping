{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T09:53:56.515030Z",
     "iopub.status.busy": "2024-03-16T09:53:56.514483Z",
     "iopub.status.idle": "2024-03-16T09:53:59.080806Z",
     "shell.execute_reply": "2024-03-16T09:53:59.079770Z",
     "shell.execute_reply.started": "2024-03-16T09:53:56.514998Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.transforms import Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "from paddle import nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "def main(args):\n",
    "    # 使用 args 中的参数来替换原来直接写在代码中的部分\n",
    "    select_gt_path = args.select_gt_path\n",
    "    select_rs_path = args.select_rs_path\n",
    "    train_ratio = args.train_ratio\n",
    "    epochs = args.epochs\n",
    "    batch_size = args.batch_size\n",
    "    learning_rate = args.learning_rate\n",
    "    save_path = args.save_path\n",
    "\n",
    "def getTrainTest(label, trainNum):\n",
    "    # 设置随机种子\n",
    "    random.seed(32)\n",
    "    testGt = copy.deepcopy(label)\n",
    "    trainGt = np.zeros(label.shape)\n",
    "    labelNum = int(max(label.ravel())) + 1\n",
    "    for lab in range(1, labelNum):\n",
    "        labIndex = np.where(label == lab)\n",
    "        randomList = random.sample(range(0, len(labIndex[0])), int(len(labIndex[0])*trainNum))\n",
    "        for randInt in randomList:\n",
    "            x = labIndex[0][randInt]\n",
    "            y = labIndex[1][randInt]\n",
    "            trainGt[x][y] = lab\n",
    "            testGt[x][y] = 0\n",
    "    trainGt = trainGt.astype(int)\n",
    "    testGt = testGt.astype(int)\n",
    "    # drawGT(testGt, \"test_gt.jpg\")\n",
    "    # drawGT(trainGt, \"train_gt.jpg\")\n",
    "    return trainGt, testGt\n",
    "\n",
    "select_gt = np.load('/home/aistudio/npys/t30uxv/select_gt.npy').astype(int)\n",
    "select_rs = np.load('/home/aistudio/npys/t30uxv/select_rs.npy')\n",
    "train_gt , test_gt = getTrainTest(select_gt, 0.05)\n",
    "\n",
    "# 数据预处理：归一化\n",
    "def normalize_data(select_rs):\n",
    "    scaler = MinMaxScaler()\n",
    "    H, W, C, T = select_rs.shape\n",
    "    select_rs_reshaped = select_rs.reshape(-1, C)\n",
    "    select_rs_normalized = scaler.fit_transform(select_rs_reshaped)\n",
    "    select_rs_normalized = select_rs_normalized.reshape(H, W, C, T)\n",
    "    return select_rs_normalized, scaler\n",
    "\n",
    "def remap_labels(gt):\n",
    "    # 将标签0映射为-1，其他标签减1\n",
    "    remapped_gt = np.where(gt == 0, -1, gt - 1)\n",
    "    \n",
    "    # 计算映射后的唯一标签数量\n",
    "    unique_labels = np.unique(remapped_gt)\n",
    "    num_classes = len(unique_labels)\n",
    "    \n",
    "    return remapped_gt, num_classes-1\n",
    "\n",
    "\n",
    "class RSDataset(Dataset):\n",
    "    def __init__(self, rs_data, gt_data=None):\n",
    "        # 假设rs_data的原始格式是H*W*C*T\n",
    "        # 需要先将数据转换为T*C*H*W\n",
    "        self.rs_data = rs_data.transpose((3, 2, 0, 1))  # 调整为T*C*H*W\n",
    "        self.gt_data = gt_data\n",
    "        self.H, self.W = rs_data.shape[:2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.H * self.W\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = idx // self.W\n",
    "        col = idx % self.W\n",
    "        # 对于每个像素点，获取其所有时间点的数据，现在格式为T*C\n",
    "        sequence = self.rs_data[:, :, row, col].astype('float32')  # 获取T*C序列\n",
    "        if self.gt_data is not None:\n",
    "            label = self.gt_data[row, col]\n",
    "            # 直接返回序列和标签，不对标签值进行特殊处理\n",
    "            return sequence, label\n",
    "        else:\n",
    "            return sequence, np.array([row, col], dtype='float32')\n",
    "\n",
    "\n",
    "class DCM(nn.Layer):\n",
    "    def __init__(\n",
    "        self, seed, input_feature_size, hidden_size, num_layers,\n",
    "        bidirectional, dropout, num_classes\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._set_reproducible(seed)\n",
    "\n",
    "        # 修正：使用`dropout`参数而非`dropout_prob`\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_feature_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            direction='bidirectional' if bidirectional else 'forward',\n",
    "            dropout=dropout if num_layers > 1 else 0,  # 当num_layers大于1时才设置dropout\n",
    "            time_major=False\n",
    "        )  # i/o: (batch, seq_len, num_directions*hidden_size)\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        self.attention = nn.Linear(\n",
    "            in_features=num_directions * hidden_size,\n",
    "            out_features=1,\n",
    "        )\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=num_directions * hidden_size,\n",
    "            out_features=num_classes,\n",
    "        )\n",
    "\n",
    "    def _set_reproducible(self, seed, cudnn=False):\n",
    "        paddle.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        if cudnn:\n",
    "            paddle.set_flags({'FLAGS_cudnn_deterministic': True})\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attn_weights = F.softmax(F.relu(self.attention(lstm_out)), axis=1)\n",
    "        fc_in = paddle.bmm(attn_weights.transpose([0, 2, 1]), lstm_out)\n",
    "        fc_out = self.fc(fc_in)\n",
    "        return fc_out.squeeze()\n",
    "\n",
    "\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    计算OA, AA, Kappa和mIoU\n",
    "    \"\"\"\n",
    "    # 整体准确率 OA\n",
    "    oa = accuracy_score(true_labels, predicted_labels)\n",
    "    # Kappa 系数\n",
    "    kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
    "    # 混淆矩阵\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    # 每类的准确率\n",
    "    acc_per_class = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "    # 平均准确率 AA\n",
    "    aa = np.mean(acc_per_class)\n",
    "    # 每类的IoU\n",
    "    iou_per_class = conf_matrix.diagonal() / (conf_matrix.sum(axis=1) + conf_matrix.sum(axis=0) - conf_matrix.diagonal())\n",
    "    # 平均IoU mIoU\n",
    "    miou = np.mean(iou_per_class)\n",
    "    return oa, aa, kappa, miou, acc_per_class  # 确保返回每类的准确率\n",
    "\n",
    "def evaluate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for data, label in data_loader:\n",
    "        data = paddle.to_tensor(data)\n",
    "        output = model(data)\n",
    "        preds = output.argmax(axis=1).numpy()\n",
    "        valid_idx = label != -1  # 有效索引，即非-1标签\n",
    "        all_preds.extend(preds[valid_idx].flatten())\n",
    "        all_labels.extend(label.numpy()[valid_idx].flatten())\n",
    "    return calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "\n",
    "best_oa = -1  # 全局变量用于跟踪最佳OA\n",
    "\n",
    "# 训练和评估模型，同时保存OA最高时的模型参数和指标\n",
    "def train_and_evaluate(model, train_loader, test_loader, optimizer, loss_fn, epochs, save_path):\n",
    "    global best_oa\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_id, (data, label) in enumerate(train_loader):\n",
    "            data = paddle.to_tensor(data)\n",
    "            label = paddle.to_tensor(label, dtype='int64')\n",
    "            optimizer.clear_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.numpy()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        oa, aa, kappa, miou, _ = evaluate_metrics(model, test_loader)\n",
    "        if oa > best_oa:\n",
    "            best_oa = oa\n",
    "            best_model_path = os.path.join(save_path, \"model_param.pdparams\")\n",
    "            paddle.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}]: New best model saved at {best_model_path} with OA: {best_oa:.4f}\")\n",
    "\n",
    "\n",
    "def final_test_evaluation(model, test_loader, save_path):\n",
    "    best_model_path = os.path.join(save_path, \"model_param.pdparams\")\n",
    "    model_state_dict = paddle.load(best_model_path)\n",
    "    model.set_state_dict(model_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with paddle.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = paddle.to_tensor(data)\n",
    "            output = model(data)\n",
    "            preds = output.argmax(axis=1).numpy()\n",
    "            valid_idx = label.numpy() != -1\n",
    "            all_preds.extend(preds[valid_idx].flatten())\n",
    "            all_labels.extend(label.numpy()[valid_idx].flatten())\n",
    "\n",
    "    oa, aa, kappa, miou, acc_per_class = calculate_metrics(all_labels, all_preds)\n",
    "    np.save(os.path.join(save_path, \"pre_label.npy\"), np.array(all_preds))\n",
    "    \n",
    "    with open(os.path.join(save_path, \"evaluation_metric.txt\"), \"w\") as f:\n",
    "        f.write(f\"OA: {oa*100:.2f}%\\n\")\n",
    "        f.write(f\"AA: {aa*100:.2f}%\\n\")\n",
    "        f.write(f\"Kappa: {kappa*100:.2f}%\\n\")\n",
    "        f.write(f\"mIoU: {miou*100:.2f}%\\n\")\n",
    "        for i, acc in enumerate(acc_per_class):\n",
    "            f.write(f\"class{i+1}: {acc*100:.2f}%\\n\")\n",
    "\n",
    "\n",
    "# 数据集和训练比例的列表\n",
    "datasets = ['t31tfj', 't31tfm', 't31tfm_1', 't32ulu']\n",
    "train_ratios = [0.5, 0.2, 0.1, 0.05, 0.02, 0.01]\n",
    "\n",
    "for dataset in datasets:\n",
    "    select_gt_path = f'/home/aistudio/npys/{dataset}/select_gt.npy'\n",
    "    select_rs_path = f'/home/aistudio/npys/{dataset}/select_rs.npy'\n",
    "    select_gt = np.load(select_gt_path).astype(int)\n",
    "    select_rs = np.load(select_rs_path)\n",
    "\n",
    "    for train_ratio in train_ratios:\n",
    "        print(f\"Processing dataset {dataset} with train ratio {train_ratio}\")\n",
    "        train_gt, test_gt = getTrainTest(select_gt, train_ratio)\n",
    "        select_rs_normalized, _ = normalize_data(select_rs)\n",
    "        train_gt_remapped, num_classes = remap_labels(train_gt)\n",
    "        test_gt_remapped, _ = remap_labels(test_gt)\n",
    "\n",
    "        train_dataset = RSDataset(select_rs_normalized, train_gt_remapped)\n",
    "        test_dataset = RSDataset(select_rs_normalized, test_gt_remapped)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = DCM(seed=313, input_feature_size=select_rs_normalized.shape[2], hidden_size=256, num_layers=2, bidirectional=True, dropout=0.5, num_classes=num_classes)\n",
    "        optimizer = paddle.optimizer.Adam(learning_rate=1e-3, parameters=model.parameters())\n",
    "        loss_fn = paddle.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        save_path = f'/home/aistudio/DCM/{dataset}/{train_ratio}'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        best_oa = -1  # 重置最佳OA\n",
    "        train_and_evaluate(model, train_loader, test_loader, optimizer, loss_fn, 200, save_path)\n",
    "        final_test_evaluation(model, test_loader, save_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--select_gt_path', type=str, required=True, help='路径到 select_gt.npy 文件')\n",
    "    parser.add_argument('--select_rs_path', type=str, required=True, help='路径到 select_rs.npy 文件')\n",
    "    parser.add_argument('--train_ratio', type=float, required=True, help='训练集的比例')\n",
    "    parser.add_argument('--epochs', type=int, default=200, help='训练周期数')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='批处理大小')\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-3, help='学习率')\n",
    "    parser.add_argument('--save_path', type=str, required=True, help='模型和指标保存的路径')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
